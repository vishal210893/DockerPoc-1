<dependencies>
    <!-- Apache Iceberg Core -->
    <dependency>
        <groupId>org.apache.iceberg</groupId>
        <artifactId>iceberg-core</artifactId>
        <version>1.4.2</version> <!-- Use latest stable version -->
    </dependency>

    <!-- Iceberg AWS support -->
    <dependency>
        <groupId>org.apache.iceberg</groupId>
        <artifactId>iceberg-aws</artifactId>
        <version>1.4.2</version>
    </dependency>

    <!-- Apache Iceberg Hadoop support (needed for FileIO) -->
    <dependency>
        <groupId>org.apache.iceberg</groupId>
        <artifactId>iceberg-hadoop</artifactId>
        <version>1.4.2</version>
    </dependency>

    <!-- AWS SDK (optional, for AWS Glue or auth) -->
    <dependency>
        <groupId>software.amazon.awssdk</groupId>
        <artifactId>s3</artifactId>
        <version>2.25.0</version>
    </dependency>
</dependencies>


package com.example.iceberg.service;

import org.apache.iceberg.*;
import org.apache.iceberg.catalog.Catalog;
import org.apache.iceberg.catalog.TableIdentifier;
import org.apache.iceberg.hadoop.HadoopCatalog;
import org.apache.iceberg.hadoop.HadoopTables;
import org.apache.iceberg.data.Record;
import org.apache.iceberg.data.parquet.GenericParquetReaders;
import org.apache.hadoop.conf.Configuration;
import org.springframework.stereotype.Service;

import java.io.IOException;
import java.util.ArrayList;
import java.util.List;

@Service
public class IcebergReaderService {

    private static final String WAREHOUSE_PATH = "s3a://your-bucket/iceberg/warehouse";

    public List<Record> readTable(String database, String tableName) {
        List<Record> records = new ArrayList<>();

        Configuration hadoopConf = new Configuration();
        hadoopConf.set("fs.s3a.aws.credentials.provider", "com.amazonaws.auth.DefaultAWSCredentialsProviderChain");
        hadoopConf.set("fs.s3a.impl", "org.apache.hadoop.fs.s3a.S3AFileSystem");

        // Use HadoopCatalog or GlueCatalog depending on setup
        Catalog catalog = new HadoopCatalog(hadoopConf, WAREHOUSE_PATH);
        TableIdentifier tableId = TableIdentifier.of(database, tableName);

        Table table = catalog.loadTable(tableId);

        try (CloseableIterable<Record> iterable = IcebergGenerics.read(table).build()) {
            for (Record record : iterable) {
                records.add(record);
            }
        } catch (IOException e) {
            throw new RuntimeException("Failed to read records from table: " + tableName, e);
        }

        return records;
    }
}

package com.example.iceberg.service;

import org.apache.iceberg.*;
import org.apache.iceberg.aws.glue.GlueCatalog;
import org.apache.iceberg.data.Record;
import org.apache.iceberg.hadoop.HadoopFileIO;
import org.apache.iceberg.io.CloseableIterable;
import org.apache.hadoop.conf.Configuration;
import org.springframework.stereotype.Service;

import java.io.IOException;
import java.util.ArrayList;
import java.util.List;

@Service
public class IcebergReaderService {

    private static final String WAREHOUSE_PATH = "s3://your-bucket/iceberg/warehouse";

    public List<Record> readTable(String database, String tableName) {
        List<Record> records = new ArrayList<>();

        Configuration hadoopConf = new Configuration();
        hadoopConf.set("fs.s3a.aws.credentials.provider", "com.amazonaws.auth.DefaultAWSCredentialsProviderChain");
        hadoopConf.set("fs.s3a.impl", "org.apache.hadoop.fs.s3a.S3AFileSystem");

        // GlueCatalog setup
        GlueCatalog catalog = new GlueCatalog();
        catalog.setConf(hadoopConf);
        catalog.initialize("glue", ImmutableMap.of(
                "warehouse", WAREHOUSE_PATH,
                "io-impl", HadoopFileIO.class.getName()
        ));

        TableIdentifier tableId = TableIdentifier.of(database, tableName);
        Table table = catalog.loadTable(tableId);

        try (CloseableIterable<Record> iterable = IcebergGenerics.read(table).build()) {
            for (Record record : iterable) {
                records.add(record);
            }
        } catch (IOException e) {
            throw new RuntimeException("Failed to read records from table: " + tableName, e);
        }

        return records;
    }
}

package com.example.iceberg.service;

import org.apache.iceberg.Table;
import org.apache.iceberg.catalog.Catalog;
import org.apache.iceberg.catalog.TableIdentifier;
import org.apache.iceberg.data.Record;
import org.apache.iceberg.aws.glue.GlueCatalog;
import org.apache.iceberg.aws.AwsProperties;
import org.apache.iceberg.aws.s3.S3FileIO;
import org.apache.iceberg.io.CloseableIterable;
import org.apache.iceberg.CatalogProperties;
import org.apache.iceberg.io.FileIO;
import software.amazon.awssdk.auth.credentials.DefaultCredentialsProvider;
import software.amazon.awssdk.services.glue.GlueClient;
import software.amazon.awssdk.services.s3.S3Client;

import java.io.IOException;
import java.util.*;

import org.springframework.stereotype.Service;

@Service
public class IcebergReaderService {

    private static final String WAREHOUSE_PATH = "s3://your-bucket/iceberg/";

    public List<Record> readTable(String database, String tableName) {
        List<Record> records = new ArrayList<>();

        // Use DefaultCredentialsProvider
        var credentialsProvider = DefaultCredentialsProvider.create();

        // Glue client
        GlueClient glueClient = GlueClient.builder()
                .credentialsProvider(credentialsProvider)
                .build();

        // S3 client
        S3Client s3Client = S3Client.builder()
                .credentialsProvider(credentialsProvider)
                .build();

        // S3FileIO using the S3Client
        S3FileIO fileIO = new S3FileIO();
        fileIO.initialize(Map.of(), s3Client);

        // GlueCatalog with custom FileIO
        GlueCatalog catalog = new GlueCatalog();
        catalog.setGlueClient(glueClient);
        catalog.setFileIO(fileIO);
        catalog.initialize("glue", Map.of(
                CatalogProperties.WAREHOUSE_LOCATION, WAREHOUSE_PATH
        ));

        TableIdentifier tableId = TableIdentifier.of(database, tableName);
        Table table = catalog.loadTable(tableId);

        try (CloseableIterable<Record> rows = IcebergGenerics.read(table).build()) {
            rows.forEach(records::add);
        } catch (IOException e) {
            throw new RuntimeException("Failed to read from Iceberg table", e);
        }

        return records;
    }
}





List<Record> records = new ArrayList<>();

        // Create a custom AWS Client Factory using DefaultCredentialsProvider
        AwsClientFactory customClientFactory = new AwsClientFactory() {
            private final DefaultCredentialsProvider creds = DefaultCredentialsProvider.create();

            @Override
            public S3Client s3() {
                return S3Client.builder().credentialsProvider(creds).build();
            }

            @Override
            public GlueClient glue() {
                return GlueClient.builder().credentialsProvider(creds).build();
            }
        };

        // Setup properties for GlueCatalog
        Map<String, String> catalogProperties = new HashMap<>();
        catalogProperties.put(CatalogProperties.WAREHOUSE_LOCATION, WAREHOUSE_PATH);
        catalogProperties.put(CatalogProperties.FILE_IO_IMPL, S3FileIO.class.getName());
        catalogProperties.put(AwsProperties.CLIENT_FACTORY, customClientFactory.getClass().getName());

        // Register factory manually (since it's not loaded via ServiceLoader in this context)
        AwsClientFactory.register(customClientFactory);

        // Initialize GlueCatalog
        GlueCatalog catalog = new GlueCatalog();
        catalog.initialize("glue", catalogProperties);

        TableIdentifier tableId = TableIdentifier.of(database, tableName);
        Table table = catalog.loadTable(tableId);

        try (CloseableIterable<Record> rows = IcebergGenerics.read(table).build()) {
            rows.forEach(records::add);
        } catch (IOException e) {
            throw new RuntimeException("Failed to read from Iceberg table", e);
        }

        return records;

